{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY77J0ZNKU81"
      },
      "source": [
        "# Working with Datasets Libary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hCOFA_2_1uDN"
      },
      "outputs": [],
      "source": [
        "#It loads a dataset from the HuggingFace Hub\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or_Ys4yLRyB0"
      },
      "source": [
        "Datasets migth have several configurations. For instances, The GLUE dataset as an agregated benchmark has 10 subsets (as of writing this notebook) as: COLA, SST2, MRPC, QQP, STSB, MNLI, QNLI, RTE, WNLI and the diagnostic subset AX. \n",
        "\n",
        "To access each glue dataset, we pass two arguments where the first is **'glue'** and second is a **sub-part** of it to be chosen. Likewise, the wikipedia dataset have several configuration provided for several languages.\n",
        "\n",
        "Lets load 'cola' subset of GLUE as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhIhwzqgrs0D",
        "outputId": "169b419c-112b-49c5-a294-d84735dde6dc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df77808187134bedab1c620ac2eb93d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/31.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac931c1799a84c988a3aa10700a671e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0f18a3e6d064f788632783f17e17410",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/251k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afbcc206c7c54abaaf78dbda878c145a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/37.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5408365bed774f8d828380cb67e0c99d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/37.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "639d098e75a94eb7904a632b74f1d618",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fa7a8cd97f848b491375277491d7d41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/8551 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "590d1a2eceb642339034588a88691e9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/1043 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "188cbb8f915f43089e358604d5942372",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1063 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'sentence': ['They drank the pub.',\n",
              "  'The professor talked us into a stupor.',\n",
              "  'The professor talked us.',\n",
              "  'We yelled ourselves hoarse.'],\n",
              " 'label': [0, 1, 0, 1],\n",
              " 'idx': [18, 19, 20, 21]}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cola = load_dataset('glue', 'cola')\n",
        "cola['train'][18:22]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRJGcaMc0dJU"
      },
      "source": [
        "While some dataset comes with DatasetDict object, some can be of type Dataset depending on splitting condition. The CoLA dataset come with DatasetDict where we have 3 splits: train,validation, and test. Train and validation datasets include the labels as well (1: Acceptable, 0: Unacceptable), but the label values of test split are -1, which means 'no-label'.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c27Sie9lGwmj",
        "outputId": "d80f24cb-c0a3-44a1-bf03-edc722c2f406"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 8551\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 1043\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 1063\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cola"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_dFvOxzsz_S",
        "outputId": "d2f071c5-9a5e-4695-82ac-9c0d5f92856c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'idx': 12, 'label': 1, 'sentence': 'Bill rolled out of the room.'}"
            ]
          },
          "execution_count": 120,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cola['train'][12]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24epGtdbs48Y",
        "outputId": "c466bfec-f2cc-4735-c546-e642aa4ab493"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'idx': 68,\n",
              " 'label': 0,\n",
              " 'sentence': 'Which report that John was incompetent did he submit?'}"
            ]
          },
          "execution_count": 121,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cola['validation'][68]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCVXKYML1Ipg",
        "outputId": "b43680c3-e9ed-4d6f-9ba9-8133aa34913b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'idx': 20, 'label': -1, 'sentence': 'Has John seen Mary?'}"
            ]
          },
          "execution_count": 122,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cola['test'][20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StSGBLuhJSIX"
      },
      "source": [
        "## Metadata of Datasets\n",
        "* split\n",
        "* description\n",
        "* citation\n",
        "* homepage\n",
        "* license\n",
        "* info\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4H4xeA7JTwT",
        "outputId": "8a95df66-8831-4d25-f426-2ea9e7aae191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train\n",
            "GLUE, the General Language Understanding Evaluation benchmark\n",
            "(https://gluebenchmark.com/) is a collection of resources for training,\n",
            "evaluating, and analyzing natural language understanding systems.\n",
            "\n",
            "\n",
            "@article{warstadt2018neural,\n",
            "  title={Neural Network Acceptability Judgments},\n",
            "  author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},\n",
            "  journal={arXiv preprint arXiv:1805.12471},\n",
            "  year={2018}\n",
            "}\n",
            "@inproceedings{wang2019glue,\n",
            "  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n",
            "  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n",
            "  note={In the Proceedings of ICLR.},\n",
            "  year={2019}\n",
            "}\n",
            "\n",
            "https://nyu-mll.github.io/CoLA/\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(cola[\"train\"].split)\n",
        "print(cola[\"train\"].description)\n",
        "print(cola[\"train\"].citation)\n",
        "print(cola[\"train\"].homepage)\n",
        "print(cola[\"train\"].license)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wce0ixTa1IBW"
      },
      "source": [
        "### Loading other datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnshcHTRs4_K",
        "outputId": "a09a5f10-4f3e-49fe-8be8-66e0e5dc1875"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ]
        }
      ],
      "source": [
        "sst2 = load_dataset('glue', 'sst2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt0IsbSys5Bn",
        "outputId": "e37d70f1-1ba3-4b5a-b3a7-b36e8b4a1bc9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ]
        }
      ],
      "source": [
        "mrpc = load_dataset('glue', 'mrpc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X3n64WwL2Pt"
      },
      "source": [
        "To check entire subsets, run the following piece of code\n",
        "\n",
        "\n",
        "```\n",
        "glue=['cola', 'sst2', 'mrpc', 'qqp', 'stsb', 'mnli', 'mnli_mismatched', 'mnli_matched', 'qnli', 'rte', 'wnli', 'ax']\n",
        "for g in glue:\n",
        " _=load_dataset('glue', g)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY8ytQiLMKG5"
      },
      "source": [
        "## Listing all datasets and metrics in the hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwUjI5XysDjh",
        "outputId": "3899bdca-4197-452b-f164-633f382ed892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "995 datasets and 27 metrics exists in the hub\n",
            "\n",
            "['acronym_identification', 'ade_corpus_v2', 'adversarial_qa', 'aeslc',\n",
            " 'afrikaans_ner_corpus', 'ag_news', 'ai2_arc', 'air_dialogue',\n",
            " 'ajgt_twitter_ar', 'allegro_reviews', 'allocine', 'alt', 'amazon_polarity',\n",
            " 'amazon_reviews_multi', 'amazon_us_reviews', 'ambig_qa', 'amttl', 'anli',\n",
            " 'app_reviews', 'aqua_rat']\n",
            "['accuracy', 'bertscore', 'bleu', 'bleurt', 'cer', 'comet', 'coval', 'cuad',\n",
            " 'f1', 'gleu', 'glue', 'indic_glue', 'matthews_correlation', 'meteor',\n",
            " 'pearsonr', 'precision', 'recall', 'rouge', 'sacrebleu', 'sari', 'seqeval',\n",
            " 'spearmanr', 'squad', 'squad_v2', 'super_glue', 'wer', 'xnli']\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "from datasets import list_datasets, list_metrics\n",
        "all = list_datasets()\n",
        "metrics = list_metrics()\n",
        "\n",
        "print(f\"{len(all)} datasets and {len(metrics)} metrics exists in the hub\\n\")\n",
        "pprint(all[:20], compact=True)\n",
        "pprint(metrics, compact=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YullrhmI5lHO"
      },
      "source": [
        "## Selecting, sorting, filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azBvXH8F3uYk"
      },
      "source": [
        "### Split\n",
        "which split of the data to be loaded. If None by default, will return a `dict` with all splits (Train, Test, Validation or any other).  If split is specified, it will return a single Dataset rather than a Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gyi_LgUPVtq",
        "outputId": "17d7fae8-8807-4596-d063-dd36e0798d63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ]
        }
      ],
      "source": [
        "cola = load_dataset('glue', 'cola', split ='train[:300]+validation[-30%:]')\n",
        "# Which means the first 300 examples of train  plus the last 30% of validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnncU49m4V9q"
      },
      "source": [
        "#### Other Split Examples\n",
        "The first 100 examples from train and validation\n",
        "\n",
        "`split='train[:100]+validation[:100]'` \n",
        "\n",
        "50% of train and 30 % of validation\n",
        "\n",
        "`split='train[:50%]+validation[:30%]'`\n",
        "\n",
        "\n",
        "The first 20% of train and examples in the slice 30:50 from validation\n",
        "\n",
        "`split='train[:20%]+validation[30:50]'`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4x7vJIh-697"
      },
      "source": [
        "### Sorting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57MIyMY0_PWq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZMNeQfe-7Uw",
        "outputId": "940c9d5a-4483-4e80-9f3e-d6789dfadc32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached sorted indices for dataset at /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-54fbf680867c6dca.arrow\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "execution_count": 131,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cola.sort('label')['label'][:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvUxINYb_BWH",
        "outputId": "e043ce46-b054-4d5c-8b90-7956bb2802bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached sorted indices for dataset at /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-54fbf680867c6dca.arrow\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
            ]
          },
          "execution_count": 132,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cola.sort('label')['label'][-15:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "f-VVYvtU_Qku"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DZ7T9-h_R5O"
      },
      "source": [
        "###  Indexing\n",
        "You can also access several rows using slice notation or with a list of indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ukx2v_b6AHW1"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoqiXsjf_yBV",
        "outputId": "e6c9762b-3e9f-4adb-f197-3c3d7c2aa6b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'idx': [6, 19, 44],\n",
              " 'label': [1, 1, 1],\n",
              " 'sentence': ['Fred watered the plants flat.',\n",
              "  'The professor talked us into a stupor.',\n",
              "  'The trolley rumbled through the tunnel.']}"
            ]
          },
          "execution_count": 133,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cola[6,19,44]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eAbIIMR_6CW",
        "outputId": "f7ee506a-b937-4737-892d-0d9dfd6425f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'idx': [42, 43, 44, 45],\n",
              " 'label': [0, 1, 1, 1],\n",
              " 'sentence': ['They made him to exhaustion.',\n",
              "  'They made him into a monster.',\n",
              "  'The trolley rumbled through the tunnel.',\n",
              "  'The wagon rumbled down the road.']}"
            ]
          },
          "execution_count": 134,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cola[42:46]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kouidG0PAIg2"
      },
      "source": [
        "### Shuffling "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OQ8DLJcAKv4",
        "outputId": "e6047b2f-0c39-4aa4-89a8-8d42a6ad1c71"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-97a24a7d09391f14.arrow\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'idx': [904, 1017, 885],\n",
              " 'label': [1, 0, 1],\n",
              " 'sentence': ['Lou forgot the umbrella in the closet.',\n",
              "  'It is the problem that he is here.',\n",
              "  'I met the person who left.']}"
            ]
          },
          "execution_count": 135,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cola.shuffle(seed=42)[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5atyj-_59tJ"
      },
      "source": [
        "## Caching and reusability\n",
        "Using cache files allows us to load large datasets by means of memory mapping if datasets fit on the drive  to use a fast backend and do smart caching by saving and reusing the results of operations executed on the drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlKPEB2RccN7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xdxVno0Pguy",
        "outputId": "cc962d64-4335-4a06-e1f6-b355263527ca"
      },
      "outputs": [],
      "source": [
        "pprint(list(dir(cola)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcKjoobg7yy4",
        "outputId": "9540b76d-eed6-496b-da59-71d2bce66b48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'filename': '/root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue-train.arrow'},\n",
              " {'filename': '/root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue-validation.arrow'}]"
            ]
          },
          "execution_count": 137,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cola.cache_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN7OLqp97Mdx",
        "outputId": "265bd75e-c97e-4572-a65d-51b7ecfdb6ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetInfo(description='GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems.\\n\\n', citation='@article{warstadt2018neural,\\n  title={Neural Network Acceptability Judgments},\\n  author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},\\n  journal={arXiv preprint arXiv:1805.12471},\\n  year={2018}\\n}\\n@inproceedings{wang2019glue,\\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\\n  note={In the Proceedings of ICLR.},\\n  year={2019}\\n}\\n', homepage='https://nyu-mll.github.io/CoLA/', license='', features={'idx': Value(dtype='int32', id=None), 'label': ClassLabel(num_classes=2, names=['unacceptable', 'acceptable'], names_file=None, id=None), 'sentence': Value(dtype='string', id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name='glue', config_name='cola', version=1.0.0, splits={'train': SplitInfo(name='train', num_bytes=484873, num_examples=8551, dataset_name='glue'), 'validation': SplitInfo(name='validation', num_bytes=60326, num_examples=1043, dataset_name='glue'), 'test': SplitInfo(name='test', num_bytes=60517, num_examples=1063, dataset_name='glue')}, download_checksums={'https://dl.fbaipublicfiles.com/glue/data/CoLA.zip': {'num_bytes': 376971, 'checksum': 'f212fcd832b8f7b435fb991f101abf89f96b933ab400603bf198960dfc32cbff'}}, download_size=376971, post_processing_size=None, dataset_size=605716, size_in_bytes=982687)"
            ]
          },
          "execution_count": 138,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cola.info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVXL4bJ1BUJ1"
      },
      "source": [
        "## Dataset Filter and Map Function\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZkGts_39ISL"
      },
      "source": [
        "### Filter function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gthxqxRfG_wc",
        "outputId": "1ce5f4af-0c71-4931-e3ab-2be3bd342ec9"
      },
      "outputs": [],
      "source": [
        "# To get 3 sentences ,including the term \"kick\" with Filter\n",
        "cola = load_dataset('glue', 'cola',split='train')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f238e668111349db95e3a09f6f076f47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/8551 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Jill kicked the ball from home plate to third base.', 'Fred kicked the ball under the porch.', 'Fred kicked the ball behind the tree.']\n"
          ]
        }
      ],
      "source": [
        "print(cola.filter(lambda s: \"kick\" in s['sentence'])[\"sentence\"][:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QHMyXqVHsrt",
        "outputId": "7ddcd3bb-a4ba-4b00-c162-1cd3bbc5aa02"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3cb8595371f341f980c39cad060ed667",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/8551 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"Our friends won't buy this analysis, let alone the next one we propose.\", \"One more pseudo generalization and I'm giving up.\", \"One more pseudo generalization or I'm giving up.\"]\n"
          ]
        }
      ],
      "source": [
        "# To get 3 acceptable sentences\n",
        "print(cola.filter(lambda s: s['label']== 1 )[\"sentence\"][:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In some cases, we might not know the integer code of a class label. Suppose we have many \n",
        "classes, and the code of the culture class is hard to remember out of 10 classes. Instead \n",
        "of giving integer code 1 in our preceding example, which is the code for acceptable, \n",
        "we can pass an acceptable label to the str2int() function, as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXkjxZwnIu1o",
        "outputId": "a43edbf3-f224-4f68-fa0e-c44b2a03c413"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b0c192fc0424bb5910063d1eaaad0f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/8551 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[\"Our friends won't buy this analysis, let alone the next one we propose.\",\n",
              " \"One more pseudo generalization and I'm giving up.\",\n",
              " \"One more pseudo generalization or I'm giving up.\"]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# To get 3 acceptable sentences - alternative version\n",
        "cola.filter(lambda s: s['label']== cola.features['label'].str2int('acceptable'))[\"sentence\"][:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuxdPIGhRRp6"
      },
      "source": [
        "### Processing data with  map function\n",
        "datasets.Dataset.map() function iterates over the dataset applying a processing function to each examples in a dataset and modifies the content of the samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7hEPB9gJzcO",
        "outputId": "6917d96f-ea6e-4c5a-eeda-5389312d1c9e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c75fa3d404841119d39b6c4e1e32fd3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8551 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# E.g. adding new features\n",
        "cola_new=cola.map(lambda e: {'len': len(e['sentence'])})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBzIzv3SCr4F",
        "outputId": "9d1317a7-319e-465d-8d68-1f1de2a79fbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['sentence', 'label', 'idx', 'len'],\n",
              "    num_rows: 8551\n",
              "})"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cola_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6yZbdB3Kiyk",
        "outputId": "87075ea6-bed1-4342-c3be-265b515dc27b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sentence': [\"Our friends won't buy this analysis, let alone the next one we propose.\", \"One more pseudo generalization and I'm giving up.\", \"One more pseudo generalization or I'm giving up.\"], 'label': [1, 1, 1], 'idx': [0, 1, 2], 'len': [71, 49, 48]}\n"
          ]
        }
      ],
      "source": [
        "print(cola_new[0:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As another example, the following piece of code cut the sentence after 20 characters. We \n",
        "do not create a new feature, but instead update the content of the sentence feature, as \n",
        "follows: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV8FUZqZKxu4",
        "outputId": "796afadd-abea-498a-eb18-944e05c4708d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e486efbb40d8464d8c32c92760171256",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8551 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cola_cut=cola_new.map(lambda e: {'sentence': e['sentence'][:20]+'_'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZZ7N7tXLdU3",
        "outputId": "3561afc4-31d6-4206-e242-03e210ec7fcd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>idx</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Our friends won't bu_</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>One more pseudo gene_</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>One more pseudo gene_</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                sentence  label  idx  len\n",
              "0  Our friends won't bu_      1    0   71\n",
              "1  One more pseudo gene_      1    1   49\n",
              "2  One more pseudo gene_      1    2   48"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(cola_cut[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO1yD63jR_oX"
      },
      "source": [
        "## Working with Local Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATU9RvvRUj3t",
        "outputId": "691082ab-f89b-400e-8b4b-c4f7a57976de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1-Psk5XmYiG4",
        "outputId": "e06a96e6-c72a-43ab-aad1-0d95f3a6f877"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/akademi/Packt NLP with Transformers/CH02'"
            ]
          },
          "execution_count": 148,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13plSMLLYs4m",
        "outputId": "81d63d95-35ac-4744-e381-cc3079e3879b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['CH02b_Working_with_Datasets_Libary.ipynb',\n",
              " 'data',\n",
              " 'CH02a_Working_with_Language_Models_and_Tokenizers.mp4',\n",
              " 'CH02a_Working_with_Language_Models_and_Tokenizers .ipynb',\n",
              " 'CH02c_Speed_and_Memory_Benchmarking.ipynb']"
            ]
          },
          "execution_count": 149,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(\"/content/drive/My Drive/akademi/Packt NLP with Transformers/CH02\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "OsAmx8r5U5WC"
      },
      "outputs": [],
      "source": [
        "if os.getcwd()!='/content/drive/My Drive/akademi/Packt NLP with Transformers/CH02':\n",
        "    os.chdir(\"drive/MyDrive/akademi/Packt NLP with Transformers/CH02\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_lj0qbmrY6jo",
        "outputId": "3e9bbfcf-cc27-4706-ca9c-6c441fa24612"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/akademi/Packt NLP with Transformers/CH02'"
            ]
          },
          "execution_count": 151,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkJmZzW-ViHZ",
        "outputId": "5e706836-4543-45d3-97df-94c34b1238cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['CH02b_Working_with_Datasets_Libary.ipynb',\n",
              " 'data',\n",
              " 'CH02a_Working_with_Language_Models_and_Tokenizers.mp4',\n",
              " 'CH02a_Working_with_Language_Models_and_Tokenizers .ipynb',\n",
              " 'CH02c_Speed_and_Memory_Benchmarking.ipynb']"
            ]
          },
          "execution_count": 152,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "AoBmadKXSDSS"
      },
      "outputs": [],
      "source": [
        "# To load a dataset from local files CSV, TXT, JSON, a generic loading scripts are provided "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS_d1XDESVDT",
        "outputId": "0c6ee4c3-4059-4e02-8aa7-ea18822c73ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-811df5c9519fddd3\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-811df5c9519fddd3/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n",
            "Using custom data configuration default-37a89142f75f1c5a\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-37a89142f75f1c5a/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n",
            "Using custom data configuration default-6468b1b0b5900944\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-6468b1b0b5900944/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n"
          ]
        }
      ],
      "source": [
        "# under data folder there are the files[a.csv, b.csv, c.csv], some random part of SST-2 dataset\n",
        "from datasets import load_dataset\n",
        "data1 = load_dataset('csv', data_files='./data/a.csv', delimiter=\"\\t\")\n",
        "data2 = load_dataset('csv', data_files=['./data/a.csv','./data/b.csv', './data/c.csv'], delimiter=\"\\t\")\n",
        "data3 = load_dataset('csv', data_files={'train':['./data/a.csv','./data/b.csv'], 'test':['./data/c.csv']}, delimiter=\"\\t\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "ZeHJzioJTNt3",
        "outputId": "13187cd2-8d64-4b87-91ee-1e94e58c5a72"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hide new secretions from the parental units</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>contains no wit , only labored gags</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>that loves its characters and communicates som...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  label\n",
              "0       hide new secretions from the parental units       0\n",
              "1               contains no wit , only labored gags       0\n",
              "2  that loves its characters and communicates som...      1"
            ]
          },
          "execution_count": 155,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(data1[\"train\"][:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "b2utSTp7WYIj",
        "outputId": "35679bca-2640-4239-f7bd-e86cd2e476fd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>inane and awful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>told in scattered fashion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>takes chances that are bold by studio standards</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                          sentence\n",
              "0      0                                  inane and awful \n",
              "1      0                        told in scattered fashion \n",
              "2      1  takes chances that are bold by studio standards "
            ]
          },
          "execution_count": 156,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(data3[\"test\"][:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "BgSL1tJDZtUb"
      },
      "outputs": [],
      "source": [
        "# get the files in other format\n",
        "# data_json = load_dataset('json', data_files='a.json')\n",
        "# data_text = load_dataset('text', data_files='a.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "ZrhYk5RZcw_9"
      },
      "outputs": [],
      "source": [
        "#you can also access several rows using slice notation or with a list of indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "pNxR0MF2HCT0"
      },
      "outputs": [],
      "source": [
        "# shuffling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE3xOlHagXsC",
        "outputId": "45394197-8d4a-4d36-ff2e-0663487e5a6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/csv/default-6468b1b0b5900944/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-3a29ecf37f77eb59.arrow\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0]"
            ]
          },
          "execution_count": 160,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data3_shuf=data3['train'].shuffle(seed=42)\n",
        "data3_shuf['label'][:15]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "6GgSENedtivK"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzvvWYc_tjld"
      },
      "source": [
        "## Preparing the data for model training\n",
        "Let us take an example with a tokenizer. \n",
        "To do so, we need to install transformers library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "JD0r-dcItb3D"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "leJcuyuHtdmh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBfqdGSGBRKj"
      },
      "source": [
        "If batched is True, it provides batch of examples to any function.\n",
        "batch_size (default is 1000) is  number of instances per batch provided to a function. If not selected, the whole dataset is provided as a single batch to any given function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['sentence', 'label', 'idx'],\n",
              "    num_rows: 8551\n",
              "})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cola"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Our friends won't buy this analysis, let alone the next one we propose.\""
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cola['sentence'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MckfxQQB1ljN",
        "outputId": "b5c27f2e-e0e6-44a4-bc33-7f55767a28fe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4be7ce7a2f2348b38f0b546de6319e58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8551 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "encoded_data1 = cola.map( lambda e: tokenizer(e['sentence']), batched=True, batch_size=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5SbL4tU1qVo",
        "outputId": "6f1bfe4e-3272-4e7d-ece3-1ed5e0aa0dde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 8551\n",
              "})"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_data1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Our friends won't buy this analysis, let alone the next one we propose.\""
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_data1['sentence'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdvjGHWUzZlt",
        "outputId": "17c5dbd2-7681-4858-d21e-bd32613148b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6468b1b0b5900944/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-d1d250b2127835bc.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6468b1b0b5900944/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-99b6e3afa67cadc0.arrow\n"
          ]
        }
      ],
      "source": [
        "encoded_data3 = data3.map(lambda e: tokenizer( e['sentence'], padding=True, truncation=True, max_length=12), batched=True, batch_size=1000) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-OQEKTKeUmJ",
        "outputId": "15a2204e-ca64-4102-a2da-001ba36f81eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'label'],\n",
              "        num_rows: 199\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'sentence'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 168,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCY68Toieb69",
        "outputId": "5608c181-be6a-4247-bb44-cee557fb71d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['attention_mask', 'input_ids', 'label', 'sentence'],\n",
              "        num_rows: 199\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['attention_mask', 'input_ids', 'label', 'sentence'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 169,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_data3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPgYyTebeey4",
        "outputId": "ce084847-0172-48fa-ded0-9b902b80f6bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
            " 'input_ids': [101, 2019, 5186, 16010, 2143, 1012, 102, 0, 0, 0, 0, 0],\n",
            " 'label': 0,\n",
            " 'sentence': 'an extremely unpleasant film . '}\n"
          ]
        }
      ],
      "source": [
        "pprint(encoded_data3['test'][12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "AWekEQLreigN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CH02b_Working_with_Datasets_Libary.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
